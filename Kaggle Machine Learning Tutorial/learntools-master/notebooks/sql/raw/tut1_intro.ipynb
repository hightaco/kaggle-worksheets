{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "SQL is the programming language used with databases, and it is an important skill for any data scientist. You'll build your SQL skills in this course apply those skills using BigQuery, a database system that lets you apply SQL to huge datasets.\n",
    "\n",
    "This lesson describes basics about connecting to the database and running your first SQL query. After you have a handle on these basics, we'll come back to build your SQL skills.\n",
    "\n",
    "\n",
    "# Your First BigQuery Commands\n",
    "We'll access BigQuery using a Python package called `bq_helper` that puts BigQuery results into Pandas DataFrames. This is valuable if you are familiar with Pandas. In case you aren't, we have a separate [Pandas course](https://www.kaggle.com/learn/pandas).\n",
    "\n",
    "You can import`bq_helper` in the standard way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bq_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to create a BigQueryHelper object pointing to a specific dataset. \n",
    "\n",
    "For now, we will give you the names of the datasets you will connect to. The current example uses a dataset of posts to HackerNews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a helper object for our bigquery dataset\n",
    "hacker_news = bq_helper.BigQueryHelper(active_project= \"bigquery-public-data\", \n",
    "                                       dataset_name = \"hacker_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Schemas\n",
    "\n",
    "The structure of a dataset is called its **schema**.\n",
    "\n",
    "We need to understand a database's schema to effectively pull out the data we want (called \"querying the database\"). The `BigQueryHelper.list_tables()` method lists the tables in the dataset. A table is composed of rows and columns, like a spreadsheet table. The database itself can hold multiple tables, much as a spreadsheet file can hold multiple tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print a list of all the tables in the hacker_news dataset\n",
    "hacker_news.list_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what tables are in this dataset, we can explore the columns in individual tables. In this example, we'll look at table called \"full\". Note that other data sets have different table names, so you will not always use \"full.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print information on all the columns in the \"full\" table\n",
    "# in the hacker_news dataset\n",
    "hacker_news.table_schema(\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each SchemaField tells us about a specific column. In order, the information is:\n",
    "\n",
    "* The name of the column\n",
    "* The datatype in the column\n",
    "* [The mode of the column](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#schema.fields.mode) (NULLABLE means that a column allows NULL values, and is the default)\n",
    "* A description of the data in that column\n",
    "\n",
    "The first field has the SchemaField:\n",
    "\n",
    "`SchemaField('by', 'string', 'NULLABLE', \"The username of the item's author.\",())`\n",
    "\n",
    "This tells us \n",
    "- the field is called \"by\"\n",
    "- the data in this field is strings \n",
    "- NULL values are allowed\n",
    "- It contains the \"username\" of the item's author.\n",
    "\n",
    "We can use the `BigQueryHelper.head()` method to check just the first couple of lines of of the \"full\" table to make sure this is right. (Sometimes databases out there have outdated description, so it's good to check.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preview the first couple lines of the \"full\" table\n",
    "hacker_news.head(\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BigQueryHelper.head()` method will also let us look at just the information in a specific column. If we want to see the first ten entries in the \"by\" column, for example, we can do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preview the first ten entries in the by column of the full table\n",
    "hacker_news.head(\"full\", selected_columns=\"by\", num_rows=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrap Up\n",
    "You've seen how to:\n",
    "- Set up a helper function to access your database (`BigQueryHelper`)\n",
    "- List the tables in your database (`list_tables`)\n",
    "- Review the schema for any table (`table_schema`)\n",
    "- Inspect the top few rows in a table (`head`)\n",
    "\n",
    "You're about to get a chance to try these out. \n",
    "\n",
    "Before we go into the coding exercise, a quick disclaimer for those who already know some SQL:\n",
    "\n",
    "**Each Kaggle user can scan 5TB every 30 days for free.  Once you hit that limit, you'll have to wait for it to reset.**\n",
    "\n",
    "The commands you've seen so far won't demand a meaningful fraction of that limit. But some BiqQuery datasets are huge. So, if you already know SQL, wait to run `SELECT` queries until you've seen how to use your allotment effectively. If you are like most people reading this, you don't know how to write these queries yet, so you don't need to worry about this disclaimer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn\n",
    "Practice the commands you've seen to **[Explore The Structure of a Dataset](#$NEXT_NOTEBOOK_URL$)** with crimes in the city of Chicago."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
