{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRO\n",
    "\n",
    "**SELECT** statements or queries are the most important part of SQL.  \n",
    "\n",
    "We uses the keywords **SELECT**, **FROM** and **WHERE** to get data from specific columns based on conditions you specify. \n",
    "\n",
    "### SELECT ... FROM\n",
    "\n",
    "The most basic SQL query selects a single column from a single table. To do this, you specify the column you want after the word **SELECT** and then specify what table to pull the column from after the word **FROM**. \n",
    "\n",
    "Let's see a query in a small imaginary database, `pet_records` which has just one table in it, called `pets`.\n",
    "\n",
    "![](https://i.imgur.com/Ef4Puo3.png)\n",
    "\n",
    "\n",
    "So, if we wanted to select the `Name` column from the pets table of the pet_records database (if that database were accessible as a BigQuery dataset on Kaggle , which it is not, because I made it up), we would do this:\n",
    "\n",
    "    SELECT Name\n",
    "    FROM `bigquery-public-data.pet_records.pets`\n",
    "\n",
    "It would return the highlighted data from this figure.\n",
    "\n",
    "![](https://i.imgur.com/8FdVyFP.png)\n",
    "\n",
    "Note that the argument we pass to **FROM** is *not* in single or double quotation marks (' or \"). It is in backticks (\\`). We use to identify the relevant BigQuery data source.\n",
    "\n",
    "> **Do you need to capitalize SELECT and FROM?** No, SQL doesn't care about capitalization. However, it's customary to capitalize your SQL commands and it makes your queries a bit easier to read.\n",
    "\n",
    "\n",
    "### WHERE ...\n",
    "\n",
    "BigQuery datasets are large. So you'll usually want to return only the rows meeting specific conditions. You can do this using the **WHERE** clause:\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "    SELECT Name\n",
    "    FROM `bigquery-public-data.pet_records.pets`\n",
    "    WHERE Animal = 'Cat'\n",
    "\n",
    "This query will only return the entries from the `Name` column that are in rows where the `Animal` column has the text `Cat` in it. Those are the cells highlighted in blue in this figure:\n",
    "\n",
    "![](https://i.imgur.com/Va52Qdl.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: What are all the U.S. cities in the OpenAQ dataset?\n",
    "\n",
    "Now that you've got the basics down, let's work through an example with a real dataset. We'll use the OpenAQ dataset about air quality.\n",
    "\n",
    "First, we'll set up everything we need to run queries and take a quick peek at what tables are in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import package with helper functions \n",
    "import bq_helper\n",
    "\n",
    "# create a helper object for this dataset\n",
    "open_aq = bq_helper.BigQueryHelper(active_project=\"bigquery-public-data\",\n",
    "                                   dataset_name=\"openaq\")\n",
    "\n",
    "# print all the tables in this dataset (there's only one!)\n",
    "open_aq.list_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can peek at the first few rows to see what sort of data is in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the first couple rows of the \"global_air_quality\" dataset\n",
    "open_aq.head(\"global_air_quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good! Let's put together a query. I want to select all the values from the \"city\" column for the rows where the \"country\" column is `US` (for \"United States\"). \n",
    "\n",
    "> **What's up with the triple quotation marks (\"\"\")?** These tell Python that everything inside them is a single string, even though we have line breaks in it. The line breaks aren't necessary, but they make it easier to read your query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query to select all the items from the \"city\" column where the\n",
    "# \"country\" column is \"us\"\n",
    "query = \"\"\"SELECT city\n",
    "            FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "            WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can use this query to get information from our open_aq dataset. I'm using the `BigQueryHelper.query_to_pandas_safe()` method here because it won't run a query if it's too large. More about that soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the query_to_pandas_safe will only return a result if it's less\n",
    "# than one gigabyte (by default)\n",
    "us_cities = open_aq.query_to_pandas_safe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I've got a Pandas dataframe called us_cities, which I can use like any other dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What five cities have the most measurements taken there?\n",
    "us_cities.city.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want multiple columns, you can select them with a column between the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT city, country\n",
    "            FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "            WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select all columns of data with a `*` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT *\n",
    "            FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "            WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Working With Big Datasets\n",
    "\n",
    "BigQuery datasets can be huge. We allow you to do a lot of computation for free, but everyone has some limit. \n",
    "\n",
    "**Each Kaggle user can scan 5TB every 30 days for free.  Once you hit that limit, you'll have to wait for it to reset.**\n",
    "\n",
    "The [biggest dataset currently on Kaggle](https://www.kaggle.com/github/github-repos) is 3 terabytes, so if you aren't a little careful, you can go through your 30-day limit in a couple queries.\n",
    "\n",
    "Don't worry though: if you use `query_to_pandas_safe` you won't pull too much data at once and run over your limit.\n",
    "\n",
    "Another way to be careful is to estimate how big your query will be before you actually execute it. You can do this with the `BigQueryHelper.estimate_query_size()` method. \n",
    "\n",
    "This is better than relying on your intuition for query size, because your quota is on data *scanned*, not the amount of data returned. And it's tricky to know how much data a database will need to \"scan\" to return your results, even if you have a good sense of how large the results will be.\n",
    "\n",
    "Here's an example workflow using a big dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this query looks in the full table in the hacker_news\n",
    "# dataset, then gets the score column from every row where \n",
    "# the type column has \"job\" in it.\n",
    "query = \"\"\"SELECT score\n",
    "            FROM `bigquery-public-data.hacker_news.full`\n",
    "            WHERE type = \"job\" \"\"\"\n",
    "\n",
    "# check how big this query will be\n",
    "hacker_news.estimate_query_size(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `query_to_pandas_safe` has an optional parameter to specify how much data you are willing to scan for any specific query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this query if it's less than 100 MB\n",
    "hacker_news.query_to_pandas_safe(query, max_gb_scanned=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's an example where the same query returns a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the scores of job postings (if the \n",
    "# query is smaller than 1 gig)\n",
    "job_post_scores = hacker_news.query_to_pandas_safe(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work with the resulting DataFrame as we would any other dataframe. For example, we can get the mean of the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average score for job posts\n",
    "job_post_scores.score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn\n",
    "\n",
    "Writing SELECT statements is the key to using SQL. So **[try your new skills](#$NEXT_NOTEBOOK_URL$)**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
